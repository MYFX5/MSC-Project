{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian process with Spike and Slab ARD prior - Stage 1 Savitsky experiment\n",
    "## Zero-temperature-MF VI algorithm (continuous spike) - non additive kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Importing and defining all required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing required libraries and defining key functions\n",
    "\"\"\"\n",
    "# Requirements for algorithms\n",
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "from scipy.spatial.distance import cdist \n",
    "\n",
    "# Requirements For plots and diagnostics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import date\n",
    "import inspect\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Algorithm functions\n",
    "import os\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/GP algorithms/Master function files')\n",
    "from GP_funcs_ZTMFSS import kernel_funcs\n",
    "from GP_funcs_ZTMFSS import model_funcs\n",
    "from GP_funcs_ZTMFSS import draw_GP\n",
    "from GP_funcs_ZTMFSS import fit\n",
    "from GP_funcs_ZTMFSS import diagnostics\n",
    "from GP_funcs_ZTMFSS import simulations\n",
    "from functools import partial\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/Simulation results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Setting simulation parameters and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulation controls\n",
    "\"\"\"\n",
    "# Simulation settings\n",
    "n=100\n",
    "ntest=20\n",
    "p=1000\n",
    "q=6\n",
    "correlation = False\n",
    "nruns = 100\n",
    "\n",
    "# Model run settings\n",
    "l_init = 0.01\n",
    "beta2=0.99\n",
    "m = 7\n",
    "nmodels = 7\n",
    "VS_threshs = [[0.1**2,0.1**1.5,0.1**1,0.1**0.5,0.1**0],\n",
    "              [0.5,0.9,0.95,0.99],\n",
    "             [0.5,0.9,0.95,0.99],\n",
    "             [0.5,0.9,0.95,0.99],\n",
    "             [0.5,0.9,0.95,0.99],\n",
    "             [0.5,0.9,0.95,0.99],\n",
    "             [0.5,0.9,0.95,0.99]]\n",
    "iter_remove = [False,True,True,True,True,True,True]\n",
    "sampling_strat = [\"unif\",\"unif\", \"unif\", \"unif\", \"unif\", \"unif\", \"unif\"]\n",
    "minibatch_size = [n,25, 25,50,50,n,n]\n",
    "GPtol=[1e-10, 1e-5,1e-5,1e-5,1e-5,1e-5,1e-5]\n",
    "SS_GP=[False, True,True,True,True,True,True]\n",
    "MC_pred = [False,False,False,False,False,False,False]\n",
    "predict_selected = [False,False,False,False,False,False,False]\n",
    "post_fit = [False,False,False,False,False,False,False]\n",
    "train = [True,True,False,True, False, True,False] \n",
    "step = [0.01,0.05,0.05,0.05,0.05,0.05,0.05]\n",
    "hyper_opt = [False,True,True,True,True,True,True]\n",
    "model_select = [True,False,True,False,True,False,True]\n",
    "post_var = [False,True,True,True,True,True,True]\n",
    "model_weights = [\"\",\"elpd\", \"elpd\",\"elpd\", \"elpd\",\"elpd\", \"elpd\"]\n",
    "min_VBEM_iter = [1,3,3,3,3,3,3]\n",
    "max_VBEM_iter = [1,10,10,10,10,10,10]\n",
    "gp_iter = [500,100,100,100,100,100,100]\n",
    "opt = [\"adam\", \"amsgrad\", \"amsgrad\", \"amsgrad\", \"amsgrad\", \"amsgrad\", \"amsgrad\"]\n",
    "\n",
    "t = len(VS_threshs[0])\n",
    "kern=kernel_funcs.gaussian\n",
    "grad_kern=kernel_funcs.grad_gaussian\n",
    "NN_pred = False\n",
    "newsumgrads = False\n",
    "VBtol=0.1/p\n",
    "temp=1\n",
    "# SEE BELOW FOR ARGVALS\n",
    "\n",
    "# Storage objects\n",
    "Runtime=np.zeros((nruns, m))\n",
    "Lambda = np.zeros((nruns, m, p))\n",
    "L = np.zeros((nruns, m, p))\n",
    "L1norm=np.zeros((nruns, m))\n",
    "L2norm=np.zeros((nruns, m))\n",
    "MSE_F=np.zeros((nruns, m))\n",
    "MSE_Y=np.zeros((nruns,m))\n",
    "Acc=np.zeros((nruns,m,t))\n",
    "Weighted_Acc=np.zeros((nruns,m,t))\n",
    "TPR=np.zeros((nruns,m,t))\n",
    "TNR=np.zeros((nruns,m,t))\n",
    "PPV=np.zeros((nruns,m,t))\n",
    "NPV=np.zeros((nruns,m,t))\n",
    "MCC=np.zeros((nruns,m,t))\n",
    "AUC=np.zeros((nruns,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Running algorithm iterations, saving and displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data generated\n",
      "Noise variance is:  0.0025000000000000005\n",
      "Average data variance is:  0.9969892827714567\n",
      "0.002991199493408203\n",
      "run time is : 29.81582474708557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hughw\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py:55: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return kern(cdist(X,X, metric = \"seuclidean\", V = 1/l**2),s)\n",
      "C:\\Users\\hughw\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py:62: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return kern(cdist(X,Xtest, metric = \"seuclidean\", V = 1/l**2),s).T\n",
      "C:\\Users\\hughw\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\hughw\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\hughw\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py:2035: RuntimeWarning: invalid value encountered in true_divide\n",
      "  MCC[j,i]=(TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time is : 18.263569831848145\n",
      "run time is : 18.751848459243774\n",
      "run time is : 11.052721738815308\n",
      "run time is : 13.156780242919922\n",
      "run time is : 11.400537729263306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dbf07814af72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mtesting_algorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pred_posterior_GP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_funcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     Runtime[run], Lambda[run], L[run], L1norm[run], L2norm[run], MSE_F[run], MSE_Y[run], Acc[run], Weighted_Acc[run], TPR[run], TNR[run], PPV[run], NPV[run], AUC[run], MCC[run] = simulations.do_simulation_VBEMSSGP(\n\u001b[0m\u001b[0;32m     48\u001b[0m                                \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVB_EM_GP_SS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm_testing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting_algorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpost_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                                \u001b[0mnmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSS_GP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSS_GP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyper_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mdo_simulation_VBEMSSGP\u001b[1;34m(y, X, ftest, ytest, Xtest, q, algorithm_training, algorithm_testing, nmodels, args, arg_vals, SS_GP, order_relevant_vars, order_irrelevant_vars, VS_threshs, predict_selected, select, hyper_opt, hyper_arg, hyper_vals, ltrue, MC_pred, MC_pred_draws, post_fit, model_select, post_fit_subsample, train, model_weighting, post_var)\u001b[0m\n\u001b[0;32m   1863\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhyper_opt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m                     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1865\u001b[1;33m                     best_pair,selection_path,losses,Results =  fit.hyper_opt_SSGP(y, X, algorithm_training, algorithm_testing, hyper_arg, hyper_vals, \n\u001b[0m\u001b[0;32m   1866\u001b[0m                                                                               method =  \"ML\", training_args=args[j],training_arg_vals=arg_vals[j])\n\u001b[0;32m   1867\u001b[0m                     \u001b[0mtrain_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mhyper_opt_SSGP\u001b[1;34m(y, X, training_algorithm, testing_algorithm, hyper_arg, hyper_vals, method, folds, metric, training_args, training_arg_vals)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     \u001b[1;31m# Running training algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m                     \u001b[0mResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcurrent_training_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                     \u001b[1;31m# Determine active selections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mVB_EM_GP_SS\u001b[1;34m(y, X, l0, s0, sig0, lmbda0, logpi0, log1_pi0, v0, v1, vg, a, b, reg, learn_spike, learn_noise, min_VBEM_iter, max_VBEM_iter, max_GP_fit_iter, init_GP_iter, VBEM_tol, GP_fit_tol, subsample, sampling_strat, nn_fraction, ELBO_sample, optimisation, learn_rate, Beta, Beta2, eps, print_GP_fit, print_VBEM, timer, kern, grad_kern, ltrue, dampen_lmbda_update, newsumgrads, store_ls, temp, post_fit, learn_rate_mult_post, iter_remove, iter_remove_freq, q, seed, learn_rate_mult, X_mult, force_include, final_ELBO_sample, final_prune)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;31m# Running GP_fit algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m             l[select],s,sig,logl,L,sum_sq_grads_l[select], sum_grads_l[select],sum_sq_grads_s, sum_grads_s, sum_sq_grads_sig, sum_grads_sig=fit.GP_fit_SS_lm(\n\u001b[0m\u001b[0;32m    981\u001b[0m                         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXscale\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msig0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampling_strat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampling_strat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearn_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                         \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGP_fit_tol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeta2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mGP_fit_SS_lm\u001b[1;34m(y, X, l0, s0, sig0, reg, subsample, sampling_strat, nn_fraction, learn_noise, tol, optimisation, learn_rate, beta, beta2, eps, v_l0, v_l1, v_g, lmbda, maxiter, print_, kern, grad_kern, sum_sq_grads_l, sum_grads_l, sum_sq_grads_s, sum_grads_s, sum_sq_grads_sig, sum_grads_sig, newsumgrads, store_ls, L, temp, q, printmaxiter, X_mult)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# Getting gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m             \u001b[0mgrad_logL_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_logL_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_logL_sig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients_gp_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKtild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_l1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_l0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_kern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_kern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[1;31m# Getting step sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mget_gradients_gp_ss\u001b[1;34m(y_sample, X_sample, K, Ktild, l, s, sigma, v_l1, v_l0, v_g, lmbda, subsample, grad_kern, temp, n)\u001b[0m\n\u001b[0;32m    622\u001b[0m                 \u001b[0mXsample_i\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_kern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXsample_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m                 \u001b[0mgrad_logL_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_funcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_log_L\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_l1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mv_l0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[1;31m# Gradient wrt s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSC project\\GP algorithms\\Master function files\\GP_funcs_ZTMFSS.py\u001b[0m in \u001b[0;36mgrad_log_L\u001b[1;34m(A, G)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# Gradient of marginal likelihood (takes as input Kinvy @ Kinvy.T - Kinv) and dK/dparam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgrad_log_L\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# Marginal likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(8750)\n",
    "runlist = np.random.choice(1000,100,False) # Choose 100 random trials\n",
    "for run in range(len(runlist)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generating data and scaling data\n",
    "    \"\"\"\n",
    "    lselect=[]\n",
    "    np.random.seed(runlist[run]) # Fixing trial seed\n",
    "    t=time.time()\n",
    "    Y,F,X,e,sigma,select=draw_GP.draw_parametric_savitsky(n,ntest,p,q, correlation)\n",
    "    \n",
    "    Y = Y.reshape(n+ntest,1)\n",
    "    F = F.reshape(n+ntest,1)\n",
    "    \n",
    "    #Y = (Y-Y.mean())/Y.var()**0.5\n",
    "    #F = (F-F.mean())/F.var()**0.5\n",
    "    X = (X-X.mean(0))/X.var(0)**0.5\n",
    "\n",
    "    # Getting training and test set\n",
    "    ytest=Y[n:]\n",
    "    Xtest=X[n:]\n",
    "    ftest=F[n:]\n",
    "    y=Y[:n]\n",
    "    X=X[:n]\n",
    "    f=F[:n]\n",
    "    print(\"data generated\")\n",
    "    if lselect:\n",
    "        print(\"Length-scales are: \",lselect[select])\n",
    "    print(\"Noise variance is: \",sigma**2)\n",
    "    print(\"Average data variance is: \", np.mean(np.var(X,0)))\n",
    "    print(time.time()-t)\n",
    "    \n",
    "    \"\"\"\n",
    "    Running algorithm\n",
    "    \"\"\"\n",
    "    args=[]\n",
    "    arg_vals =[]\n",
    "    for i in range(nmodels):\n",
    "        args.append([\"seed\", \"subsample\", \"Beta2\", \"ELBO_sample\", \"learn_rate\", \"ltrue\", \"learn_spike\", \"min_VBEM_iter\", \"init_GP_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"print_VBEM\",\n",
    "             \"s0\", \"sig0\", \"newsumgrads\",\"temp\",\"v0\",\"v1\", \"max_GP_fit_iter\", \"iter_remove\", \"learn_rate_mult\", \"sampling_strat\", \"final_prune\"])\n",
    "        arg_vals.append([1, minibatch_size[i], beta2,  min(1000,n), step[i], [], False, min_VBEM_iter[i],gp_iter[i] , max_VBEM_iter[i], GPtol[i], VBtol, False, \n",
    "                 np.var(y), np.var(y)**0.5, newsumgrads,temp,1e+4,1e-4, gp_iter[i], iter_remove[i], 1, \"unif\",False])\n",
    "\n",
    "    testing_algorithm = partial(diagnostics.get_pred_posterior_GP,reg=0.01,kern = kernel_funcs.gaussian)\n",
    "\n",
    "    Runtime[run], Lambda[run], L[run], L1norm[run], L2norm[run], MSE_F[run], MSE_Y[run], Acc[run], Weighted_Acc[run], TPR[run], TNR[run], PPV[run], NPV[run], AUC[run], MCC[run] = simulations.do_simulation_VBEMSSGP(\n",
    "                               y, X, ftest, ytest, Xtest, q, algorithm_training = fit.VB_EM_GP_SS, algorithm_testing = testing_algorithm, post_var = post_var,\n",
    "                               nmodels = m, args = args, arg_vals = arg_vals, SS_GP = SS_GP, hyper_opt = hyper_opt, train = train,\n",
    "                                hyper_arg = [\"v0\",\"v1\"], hyper_vals = [1e+4*2**np.linspace(np.log2(100),-np.log2(100),11),2**np.linspace(np.log2(100),-np.log2(100),11)], order_relevant_vars = False, order_irrelevant_vars = False, \n",
    "                                VS_threshs = VS_threshs, select = select, predict_selected = predict_selected, ltrue=lselect, MC_pred = MC_pred, post_fit = post_fit, model_select = model_select,\n",
    "                                model_weighting = model_weights)\n",
    "    \n",
    "    print(\"RUN {0}\".format(run))\n",
    "    print(\"Runtime mean is:\", Runtime[:run+1].mean(0))\n",
    "    print(\"Weighted accuracy mean is:\", Weighted_Acc[:run].mean(0))\n",
    "    print(\"TPR mean is:\", TPR[:run+1].mean(0))\n",
    "    print(\"PPV mean is:\", PPV[:run+1].mean(0))\n",
    "    print(\"MCC mean is:\", MCC[:run+1].mean(0))\n",
    "    print(\"L1norm mean is:\", L1norm[:run+1].mean(0))\n",
    "    print(\"L2norm mean is:\", L2norm[:run+1].mean(0))\n",
    "    print(\"MSE_F mean is:\", MSE_F[:run+1].mean(0))\n",
    "    print(\"MSE_Y mean is:\", MSE_Y[:run+1].mean(0), \"\\n\")\n",
    "    \n",
    "    print(\"Runtime is:\", Runtime[run])\n",
    "    print(\"Weighted accuracy is:\", Weighted_Acc[run])\n",
    "    print(\"TPR is:\", TPR[run])\n",
    "    print(\"PPV is:\", PPV[run])\n",
    "    print(\"MCC is:\", MCC[run])\n",
    "    print(\"L1norm is:\", L1norm[run])\n",
    "    print(\"L2norm is:\", L2norm[run])\n",
    "    print(\"MSE_F is:\", MSE_F[run])\n",
    "    print(\"MSE_Y is:\", MSE_Y[run], \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Runtime is: [31.81874273]\n",
      "Mean MSE_F is: [0.13405923]\n",
      "Mean MSE_Y is: [0.13595038]\n",
      "Mean Acc is: [[0.98541 0.9982  0.99545 0.9949  0.994  ]]\n",
      "Mean Weighted_Acc is: [[0.94710429 0.95270959 0.62083333 0.575      0.5       ]]\n",
      "Mean TPR is: [[0.90833333 0.90666667 0.24166667 0.15       0.        ]]\n",
      "Mean TNR is: [[0.98587525 0.99875252 1.         1.         1.        ]]\n",
      "Mean PPV is: [[0.53157822 0.84333514 1.                nan        nan]]\n",
      "Mean NPV is: [[0.99943302 0.99943593 0.99544364 0.9948955  0.994     ]]\n",
      "Mean AUC is: [0.94689805]\n",
      "Mean MCC is: [[0.6447404  0.87098273 0.48326039 0.36650283 0.        ]]\n",
      "\n",
      "\n",
      "Median Runtime is: [31.89494574]\n",
      "Median MSE_F is: [0.1198013]\n",
      "Median MSE_Y is: [0.11660882]\n",
      "Median Acc is: [[0.978 0.998 0.995 0.995 0.994]]\n",
      "Median Weighted_Acc is: [[0.90610329 0.91616365 0.58333333 0.58333333 0.5       ]]\n",
      "Median TPR is: [[0.83333333 0.83333333 0.16666667 0.16666667 0.        ]]\n",
      "Median TNR is: [[0.97887324 0.99899396 1.         1.         1.        ]]\n",
      "Median PPV is: [[0.19230769 0.83333333 1.                nan        nan]]\n",
      "Median NPV is: [[0.99897331 0.99899396 0.99499499 0.99499499 0.994     ]]\n",
      "Median AUC is: [0.97677733]\n",
      "Median MCC is: [[0.39415693 0.8323273  0.40722537 0.40722537 0.        ]]\n",
      "\n",
      "\n",
      "0.25 quantile Runtime is: [32.19522285]\n",
      "0.25 quantile MSE_F is: [0.21918394]\n",
      "0.25 quantile MSE_Y is: [0.22423087]\n",
      "0.25 quantile Acc is: [[0.974 0.997 0.995 0.995 0.994]]\n",
      "0.25 quantile Weighted_Acc is: [[0.90409121 0.91566063 0.58333333 0.58333333 0.5       ]]\n",
      "0.25 quantile TPR is: [[0.83333333 0.83333333 0.16666667 0.16666667 0.        ]]\n",
      "0.25 quantile TNR is: [[0.97484909 0.99798793 1.         1.         1.        ]]\n",
      "0.25 quantile PPV is: [[0.16666667 0.71428571 1.                nan        nan]]\n",
      "0.25 quantile NPV is: [[0.99896907 0.99899295 0.99499499 0.99499499 0.994     ]]\n",
      "0.25 quantile AUC is: [0.89050973]\n",
      "0.25 quantile MCC is: [[0.36587415 0.77004137 0.40722537 0.40722537 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "namelist = [\"Runtime\", \"MSE_F\", \"MSE_Y\", \"Acc\", \"Weighted_Acc\", \"TPR\", \"TNR\", \"PPV\", \"NPV\", \"AUC\", \"MCC\"]\n",
    "objlist = [Runtime, MSE_F, MSE_Y, Acc, Weighted_Acc, TPR, TNR, PPV, NPV, AUC, MCC]\n",
    "#iters = np.random.choice(1000,100,False)\n",
    "iters = np.linspace(0,99,100).astype(int)\n",
    "\n",
    "for i in range(len(objlist)):\n",
    "    print(\"Mean {0} is:\".format(namelist[i]), np.mean(objlist[i][iters],0))\n",
    "\n",
    "print(\"\\n\")\n",
    "for i in range(len(objlist)):\n",
    "    print(\"Median {0} is:\".format(namelist[i]), np.median(objlist[i][iters],0))\n",
    "\n",
    "print(\"\\n\")\n",
    "quant = 0.25\n",
    "for i in range(len(objlist)):\n",
    "    if namelist[i] in [\"Runtime\", \"MSE_F\", \"MSE_Y\"]:\n",
    "        print(\"{1} quantile {0} is:\".format(namelist[i], quant), np.quantile(objlist[i][iters],1-quant,0))\n",
    "    else:\n",
    "        print(\"{1} quantile {0} is:\".format(namelist[i], quant), np.quantile(objlist[i][iters],quant,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = {\"Runtime\" : Runtime, \"Lambda\" : Lambda, \"L\" : L, \"L1norm\" : L1norm, \"L2norm\" : L2norm, \"MSE_F\" : MSE_F\n",
    "        , \"MSE_Y\" : MSE_Y, \"Acc\" : Acc, \"Weighted_Acc\" : Weighted_Acc, \"TPR\" :TPR, \"TNR\" : TNR, \"PPV\" : PPV, \"NPV\" : NPV, \"AUC\" : AUC, \"MCC\" : MCC}\n",
    "String = \"Stage1_Savitsky_ZT_{0}_l0={1}_b2={2}_newgrads={3}_predselect={4}_MCpred={5}_hyperopt={11}_minibatch={12}_n={6}_p={7}_q={8}_kern={9}_runs={10}\".format(\n",
    "        date.today(), l_init, beta2, newsumgrads, predict_selected[1],MC_pred[1],n,p,q,str(kern)[23:28], nruns, hyper_opt[1],minibatch_size[1])\n",
    "np.save(String, Output) # saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
