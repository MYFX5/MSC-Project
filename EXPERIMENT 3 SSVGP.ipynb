{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing in requirements for SVGP Pytorch\n",
    "\"\"\"\n",
    "import tqdm\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "\"\"\"\n",
    "Importing in libraries for SGD-SS-GP\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "Importing algorithm functions\n",
    "\"\"\"\n",
    "import os\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/GP algorithms/Master function files')\n",
    "from GP_funcs_ZTMFSS import kernel_funcs\n",
    "from GP_funcs_ZTMFSS import model_funcs\n",
    "from GP_funcs_ZTMFSS import draw_GP\n",
    "from GP_funcs_ZTMFSS import fit\n",
    "from GP_funcs_ZTMFSS import diagnostics\n",
    "from GP_funcs_ZTMFSS import simulations\n",
    "from functools import partial\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/Simulation results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model run settings\n",
    "\"\"\"\n",
    "dlist = [10,100, 1000, 10000]\n",
    "minibatch=256\n",
    "nn_fraction = 1 # toggle\n",
    "test_fraction = 1 # toggle\n",
    "NNpred=True\n",
    "nns=256\n",
    "learn_rate = 0.025\n",
    "sampling_strat = \"nn\"\n",
    "min_VBEM_iter = 5\n",
    "max_VBEM_iter = 10\n",
    "gp_iters = 100\n",
    "kern = kernel_funcs.gaussian\n",
    "grad_kern = kernel_funcs.grad_gaussian\n",
    "post_var = False\n",
    "post_cov = False\n",
    "train_largest = True\n",
    "MC=100\n",
    "learn_rate_mult = 1\n",
    "spike = 1e+4\n",
    "scale_values = 2**np.linspace(np.log2(100),-np.log2(100),11)\n",
    "\n",
    "MSE_hyperopt=True\n",
    "\n",
    "\"\"\"\n",
    "Simulation settings\n",
    "\"\"\"\n",
    "n = 10000 # toggle\n",
    "ntrain = n\n",
    "ntest = 10000\n",
    "q=2\n",
    "corrzz=0.5\n",
    "corrxz=0.5\n",
    "r2=0.75\n",
    "lin = False\n",
    "block_corr = False\n",
    "ntrial = 1\n",
    "\n",
    "\"\"\"\n",
    "Objects to store results\n",
    "\"\"\"\n",
    "names = [\"SSVGP256\",\"SSVGP128\",\"SSVGP64\"]\n",
    "nmodel = len(names)\n",
    "Lengthscales = []\n",
    "Lambdas = []\n",
    "Predictions = []\n",
    "MSerrors_Y = []\n",
    "MSerrors_F = []\n",
    "Training_times = []\n",
    "Testing_times = []\n",
    "Xtestvals = []\n",
    "Ytestvals = []\n",
    "Ftestvals = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Control panel toggle for training/testing etc.\n",
    "\"\"\"\n",
    "train = True\n",
    "test = True\n",
    "test_store = True\n",
    "plot = True\n",
    "train_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dlist)):\n",
    "    \n",
    "    p=dlist[i]\n",
    "    np.random.seed(8750)\n",
    "\n",
    "    L = np.zeros((nmodel,ntrial,p))\n",
    "    Lambda = np.zeros((nmodel,ntrial,p))\n",
    "    Preds = np.zeros((nmodel,ntrial,ntest))\n",
    "    MSE_F = np.zeros((nmodel, ntrial))\n",
    "    MSE_Y = np.zeros((nmodel, ntrial))\n",
    "    Train_time = np.zeros((nmodel, ntrial))\n",
    "    Test_time = np.zeros((nmodel, ntrial))\n",
    "    TPR = np.zeros((nmodel, ntrial))\n",
    "    PPV = np.zeros((nmodel, ntrial))\n",
    "\n",
    "    \"\"\"\n",
    "    Looping over iterations of data draws\n",
    "    \"\"\"\n",
    "    for j in range(ntrial): \n",
    "        np.random.seed(j) # Setting seed to draw data\n",
    "                   \n",
    "        \"\"\"\n",
    "        Drawing data to use for simulation\n",
    "        \"\"\"\n",
    "        Y,F,X,e,sigma,select,ntrain,ntest = draw_GP.draw_parametric_sin_2d_new2(n, ntest, p-2, 0, 1, corrxz=corrxz,corrzz=corrzz, r2=r2, lin=lin, block_corr = block_corr)\n",
    "\n",
    "        X = (X-X[:ntrain].mean(0))/X[:ntrain].var(0)**0.5\n",
    "        \n",
    "        Xtrain = X[:ntrain, :]\n",
    "        ytrain = Y[:ntrain]\n",
    "        Xtest = X[ntrain:, :]\n",
    "        ytest = Y[ntrain:]\n",
    "        ftest = F[ntrain:]\n",
    "\n",
    "        \"\"\"\n",
    "        Initialising model weight vector\n",
    "        \"\"\"\n",
    "        weights = np.zeros(11)\n",
    "        \n",
    "        \"\"\"\n",
    "        BMA (256)\n",
    "        \"\"\"\n",
    "        m=0\n",
    "        t = time.time()\n",
    "\n",
    "        # Running algorithm\n",
    "        #testing_algorithm = partial(diagnostics.get_pred_posterior_GP_NN,reg = 0.01 ,kern = kern, grad_kern = grad_kern, latents = True, pred_selected = True, post_var = False, NN=nns, print_=False)\n",
    "        m =0\n",
    "        t = time.time()\n",
    "\n",
    "        # Running algorithm\n",
    "        testing_algorithm = partial(diagnostics.get_pred_posterior_GP_NN,reg = 0.01 ,kern = kern, grad_kern = grad_kern, latents = True, pred_selected = True, post_var = False, NN=nns, print_=True, fraction = test_fraction)\n",
    "        hyper_vals = [1e+4*scale_values,1e-4*scale_values,np.linspace(0,10,11).astype(int)]\n",
    "        hyper_arg = [\"v0\",\"v1\", \"seed\"]\n",
    "        best_pair, selections, losses, Results = fit.hyper_opt_SSGP(\n",
    "                                            ytrain, Xtrain, fit.VB_EM_GP_SS, testing_algorithm, hyper_arg, hyper_vals, method =  \"ML\", folds = 5, metric = \"elbo\", \n",
    "                                            training_args=[\"store_ls\", \"print_GP_fit\", \"nn_fraction\",\"final_ELBO_sample\", \"v0\", \"seed\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"subsample\", \"sampling_strat\", \"min_VBEM_iter\",\"init_GP_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"learn_rate_mult\"], \n",
    "                                            training_arg_vals=[False, False,nn_fraction, 0,                 spike, i,        True,          False,      learn_rate,    int(minibatch),   sampling_strat ,  min_VBEM_iter, gp_iters,  max_VBEM_iter ,           1e-5,         0.1/p, learn_rate_mult])\n",
    "\n",
    "        Train_time[m,j]= time.time()-t\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Getting log predictives\n",
    "        log_predictives = np.zeros(len(Results))\n",
    "        for k in np.where(selections!=0)[0]:\n",
    "            log_predictives[k] =  diagnostics.get_pred_posterior_GP_NN_CV(ytrain,Xtrain,Results[k],0.01,kern,NN=64, fraction=1,post_var=True, print_=False, use_tree=True, leaf_size=100, seed=0)\n",
    "            print(log_predictives[k])\n",
    "        log_predictives[np.where(selections==0)[0]]=np.min(log_predictives)-1000\n",
    "        \n",
    "        # getting weights\n",
    "        min_loss = np.max(log_predictives)\n",
    "        weights = np.exp(log_predictives - min_loss)*(np.abs(log_predictives - min_loss)<=500)\n",
    "        weights = weights/weights.sum()\n",
    "\n",
    "        # getting marginal posteriors\n",
    "        Lmbda = np.zeros((len(Results), p))\n",
    "        Ls = np.zeros((len(Results), p))\n",
    "        for k in range(len(Results)):\n",
    "            Lmbda[k] = Results[k][3]\n",
    "            Ls[k] = np.abs(Results[k][0][0])         \n",
    "        PIP = Lmbda.T @ weights\n",
    "        l = Ls.T @ weights\n",
    "        \n",
    "        log_predictive_time = time.time()-t1\n",
    "\n",
    "        # getting predictions\n",
    "        BMA_preds = diagnostics.get_BMA_predictions(ytrain,Xtrain,Xtest,testing_algorithm, Results,weights, MC_samples=MC)\n",
    "        Test_time[m,j] = time.time()-t1\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        Preds[m,j,:] = BMA_preds[0].reshape(ntest,)\n",
    "        MSE_F[m,j] = (np.abs(BMA_preds[0]-ftest)**2).mean()\n",
    "        MSE_Y[m,j] = (np.abs(BMA_preds[1]-ytest)**2).mean()\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        print(\"MSE is : \", MSE_F[m,j])\n",
    "        print(\"MSE is : \", MSE_Y[m,j])\n",
    "        print(\"Time is : \", Train_time[m,j]+ Test_time[m,j])\n",
    "        \n",
    "        \"\"\"\n",
    "        BMA (128)\n",
    "        \"\"\"\n",
    "        m+=1\n",
    "        t = time.time()\n",
    "\n",
    "        # Running algorithm\n",
    "        testing_algorithm = partial(diagnostics.get_pred_posterior_GP_NN,reg = 0.01 ,kern = kern, grad_kern = grad_kern, latents = True, pred_selected = True, post_var = False, NN=nns, print_=True, fraction = test_fraction)\n",
    "        hyper_vals = [1e+4*scale_values,1e-4*scale_values,np.linspace(0,10,11).astype(int)]\n",
    "        hyper_arg = [\"v0\",\"v1\", \"seed\"]\n",
    "        best_pair, selections, losses, Results = fit.hyper_opt_SSGP(\n",
    "                                            ytrain, Xtrain, fit.VB_EM_GP_SS, testing_algorithm, hyper_arg, hyper_vals, method =  \"ML\", folds = 5, metric = \"elbo\", \n",
    "                                            training_args=[\"nn_fraction\",\"final_ELBO_sample\", \"v0\", \"seed\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"subsample\", \"sampling_strat\", \"min_VBEM_iter\",\"init_GP_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"learn_rate_mult\"], \n",
    "                                            training_arg_vals=[nn_fraction, 0, spike, i,        True,          False,      learn_rate,    int(minibatch/2),    sampling_strat ,  min_VBEM_iter, gp_iters,  max_VBEM_iter ,           1e-5,         0.1/p, learn_rate_mult])\n",
    "\n",
    "        Train_time[m,j]= time.time()-t\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Getting log predictives\n",
    "        log_predictives = np.zeros(len(Results))\n",
    "        for k in np.where(selections!=0)[0]:\n",
    "            log_predictives[k] =  diagnostics.get_pred_posterior_GP_NN_CV(ytrain,Xtrain,Results[k],0.01,kern,NN=64, fraction=n**-0.5,post_var=True, print_=False, use_tree=False, leaf_size=100, seed=0)\n",
    "            print(log_predictives[k])\n",
    "        log_predictives[np.where(selections==0)[0]]=np.min(log_predictives)-1000\n",
    "        \n",
    "        # getting weights\n",
    "        min_loss = np.max(log_predictives)\n",
    "        weights = np.exp(log_predictives - min_loss)*(np.abs(log_predictives - min_loss)<=500)\n",
    "        weights = weights/weights.sum()\n",
    "\n",
    "        # getting marginal posteriors\n",
    "        Lmbda = np.zeros((len(Results), p))\n",
    "        Ls = np.zeros((len(Results), p))\n",
    "        for k in range(len(Results)):\n",
    "            Lmbda[k] = Results[k][3]\n",
    "            Ls[k] = np.abs(Results[k][0][0])         \n",
    "        PIP = Lmbda.T @ weights\n",
    "        l = Ls.T @ weights\n",
    "\n",
    "        # getting predictions\n",
    "        BMA_preds = diagnostics.get_BMA_predictions(ytrain,Xtrain,Xtest,testing_algorithm, Results,weights, MC_samples=MC)\n",
    "        Test_time[m,j] = time.time()-t1 + log_predictive_time\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        Preds[m,j,:] = BMA_preds[0].reshape(ntest,)\n",
    "        MSE_F[m,j] = (np.abs(BMA_preds[0]-ftest)**2).mean()\n",
    "        MSE_Y[m,j] = (np.abs(BMA_preds[1]-ytest)**2).mean()\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        print(\"MSE is : \", MSE_F[m,j])\n",
    "        print(\"MSE is : \", MSE_Y[m,j])\n",
    "        print(\"Time is : \", Train_time[m,j]+ Test_time[m,j])\n",
    "        \n",
    "        \"\"\"\n",
    "        BMA (64)\n",
    "        \"\"\"\n",
    "        m+=1\n",
    "        t = time.time()\n",
    "\n",
    "        # Running algorithm\n",
    "        testing_algorithm = partial(diagnostics.get_pred_posterior_GP_NN,reg = 0.01 ,kern = kern, grad_kern = grad_kern, latents = True, pred_selected = True, post_var = False, NN=nns, print_=True, fraction = test_fraction)\n",
    "        hyper_vals = [1e+4*scale_values,1e-4*scale_values,np.linspace(0,10,11).astype(int)]\n",
    "        hyper_arg = [\"v0\",\"v1\", \"seed\"]\n",
    "        best_pair, selections, losses, Results = fit.hyper_opt_SSGP(\n",
    "                                            ytrain, Xtrain, fit.VB_EM_GP_SS, testing_algorithm, hyper_arg, hyper_vals, method =  \"ML\", folds = 5, metric = \"elbo\", \n",
    "                                            training_args=[\"nn_fraction\", \"final_ELBO_sample\", \"v0\", \"seed\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"subsample\", \"sampling_strat\", \"min_VBEM_iter\",\"init_GP_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"learn_rate_mult\"], \n",
    "                                            training_arg_vals=[nn_fraction, 0, spike, i,    True,          False,      learn_rate,    int(minibatch/4),    sampling_strat ,  min_VBEM_iter, gp_iters,  max_VBEM_iter ,           1e-5,         0.1/p, learn_rate_mult])\n",
    "\n",
    "        Train_time[m,j]= time.time()-t\n",
    "        t1 = time.time()\n",
    "\n",
    "        \n",
    "        # Getting log predictives\n",
    "        log_predictives = np.zeros(len(Results))\n",
    "        for k in np.where(selections!=0)[0]:\n",
    "            log_predictives[k] =  diagnostics.get_pred_posterior_GP_NN_CV(ytrain,Xtrain,Results[k],0.01,kern,NN=64, fraction=n**-0.5,post_var=True, print_=False, use_tree=False, leaf_size=100, seed=0)\n",
    "            print(log_predictives[k])\n",
    "        log_predictives[np.where(selections==0)[0]]=np.min(log_predictives)-1000\n",
    "        \n",
    "        # getting weights\n",
    "        min_loss = np.max(log_predictives)\n",
    "        weights = np.exp(log_predictives - min_loss)*(np.abs(log_predictives - min_loss)<=500)\n",
    "        weights = weights/weights.sum()\n",
    "\n",
    "        # getting marginal posteriors\n",
    "        Lmbda = np.zeros((len(Results), p))\n",
    "        Ls = np.zeros((len(Results), p))\n",
    "        for k in range(len(Results)):\n",
    "            Lmbda[k] = Results[k][3]\n",
    "            Ls[k] = np.abs(Results[k][0][0])         \n",
    "        PIP = Lmbda.T @ weights\n",
    "        l = Ls.T @ weights\n",
    "        \n",
    "        # getting predictions\n",
    "        BMA_preds = diagnostics.get_BMA_predictions(ytrain,Xtrain,Xtest,testing_algorithm, Results,weights, MC_samples=MC)\n",
    "        Test_time[m,j] = time.time()-t1+log_predictive_time\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        Preds[m,j,:] = BMA_preds[0].reshape(ntest,)\n",
    "        MSE_F[m,j] = (np.abs(BMA_preds[0]-ftest)**2).mean()\n",
    "        MSE_Y[m,j] = (np.abs(BMA_preds[1]-ytest)**2).mean()\n",
    "        L[m,j,:] = l\n",
    "        Lambda[m,j,:] = PIP\n",
    "        print(\"MSE is : \", MSE_F[m,j])\n",
    "        print(\"MSE is : \", MSE_Y[m,j])\n",
    "        print(\"Time is : \", Train_time[m,j]+ Test_time[m,j])\n",
    "        \n",
    "    \"\"\"\n",
    "    Storing results in master lists\n",
    "    \"\"\"\n",
    "\n",
    "    Lengthscales.append(L)\n",
    "    Lambdas.append(Lambda)\n",
    "    Predictions.append(Preds)\n",
    "    MSerrors_Y.append(MSE_Y)\n",
    "    MSerrors_F.append(MSE_F)\n",
    "    Training_times.append(Train_time)\n",
    "    Testing_times.append(Test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Results)):\n",
    "    print(Results[i][0][0][:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "Output = {\"Names\" : names, \"L\" : Lengthscales, \"Lambda\" : Lambdas,\"Preds\" : Predictions, \"MSE_Y\" : MSerrors_Y, \"MSE_F\" : MSerrors_F, \"Train_time\" : Training_times, \"Test_time\" : Testing_times}\n",
    "String = \"E3_{0}_SSVGP\".format(\n",
    "    date.today(),ntrain,ntest,dlist, corrxz, np.round(1-r2,1),minibatch,NNpred,nns, r2)\n",
    "np.save(String, Output) # saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
