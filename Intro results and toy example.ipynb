{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP sample paths, PPI testing, and results for toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing required libraries and defining key functions\n",
    "\"\"\"\n",
    "# Basic operations and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Algorithm functions\n",
    "import os\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/GP algorithms/Master function files')\n",
    "from GP_funcs_ZTMFSS import kernel_funcs\n",
    "from GP_funcs_ZTMFSS import model_funcs\n",
    "from GP_funcs_ZTMFSS import draw_GP\n",
    "from GP_funcs_ZTMFSS import fit\n",
    "from GP_funcs_ZTMFSS import diagnostics\n",
    "from GP_funcs_ZTMFSS import simulations\n",
    "from functools import partial\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/Simulation results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP sample draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 10}\n",
    "plt.rc('font', **font)\n",
    "n = 1000\n",
    "ntest = 0\n",
    "p = 1\n",
    "q=1\n",
    "corr=0\n",
    "sigma2=1\n",
    "s=[0.1,1,10]\n",
    "l=np.array([[1/10],[1],[10]])\n",
    "r2=1\n",
    "\n",
    "x = np.linspace(0,1,1000)\n",
    "x = x/np.var(x)**0.5\n",
    "\n",
    "\"\"\"\n",
    "SE-kernel\n",
    "\"\"\"\n",
    "kern = kernel_funcs.gaussian\n",
    "fig,axs = plt.subplots(3,figsize = (10/3,25/3))\n",
    "for i in range(3):\n",
    "    axs[i].set_title(r'SE kernel: $\\theta = {0}$'.format(l[i][0]))\n",
    "    for j in range(3):\n",
    "        K = kernel_funcs.ARD_lm(l[i],s[j],x.reshape(n,1),kern)\n",
    "        y = np.random.multivariate_normal(np.zeros(n),K,1)\n",
    "        axs[i].plot(x,y.T, label = r'$\\tau = {0}$'.format(s[j]))\n",
    "    if i==2:\n",
    "        axs[i].set_xlabel(\"x\")\n",
    "    axs[i].set_ylabel(\"y\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"SE_kernel\")\n",
    "\n",
    "\"\"\"\n",
    "Cauchy kernel\n",
    "\"\"\"\n",
    "kern = kernel_funcs.cauchy \n",
    "fig,axs = plt.subplots(3,figsize = (10/3,25/3))\n",
    "for i in range(3):\n",
    "    axs[i].set_title(r'Cauchy kernel: $\\theta = {0}$'.format(l[i][0]))\n",
    "    for j in range(3):\n",
    "        K = kernel_funcs.ARD_lm(l[i],s[j],x.reshape(n,1),kern)\n",
    "        y = np.random.multivariate_normal(np.zeros(n),K,1)\n",
    "        axs[i].plot(x,y.T, label = r'$\\tau = {0}$'.format(s[j]))\n",
    "    if i==2:\n",
    "        axs[i].set_xlabel(\"x\")\n",
    "    axs[i].set_ylabel(\"y\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"Cauchy_kernel\")\n",
    "\n",
    "\"\"\"\n",
    "Periodic kernel\n",
    "\"\"\"\n",
    "kern = kernel_funcs.periodic \n",
    "fig,axs = plt.subplots(3,figsize = (10/3,25/3))\n",
    "for i in range(3):\n",
    "    axs[i].set_title(r'Periodic kernel: $\\theta = {0}$'.format(l[i][0]))\n",
    "    for j in range(3):\n",
    "        K = kernel_funcs.ARD_lm(l[i],s[j],x.reshape(n,1),kern)\n",
    "        y = np.random.multivariate_normal(np.zeros(n),K,1)\n",
    "        axs[i].plot(x,y.T, label = r'$\\tau = {0}$'.format(s[j]))\n",
    "    if i==2:\n",
    "        axs[i].set_xlabel(\"x\")\n",
    "    axs[i].set_ylabel(\"y\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"Periodic_kernel\")\n",
    "\n",
    "\"\"\"\n",
    "Matern kernel\n",
    "\"\"\"\n",
    "kern = kernel_funcs.matern0 \n",
    "fig,axs = plt.subplots(3,figsize = (10/3,25/3))\n",
    "for i in range(3):\n",
    "    axs[i].set_title(r'Matern1/2 kernel: $\\theta = {0}$'.format(l[i][0]))\n",
    "    for j in range(3):\n",
    "        K = kernel_funcs.ARD_lm(l[i],s[j],x.reshape(n,1),kern)\n",
    "        y = np.random.multivariate_normal(np.zeros(n),K,1)\n",
    "        axs[i].plot(x,y.T, label = r'$\\tau = {0}$'.format(s[j]))\n",
    "    if i==2:\n",
    "        axs[i].set_xlabel(\"x\")\n",
    "    axs[i].set_ylabel(\"y\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"Matern_kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPI plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(c,v0, Elogpi=1,Elog1_pi=1):\n",
    "    return np.sqrt((np.log(1/c)+2*(Elog1_pi-Elogpi))/(v0*(1-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_c = 100\n",
    "n_v0 = 10\n",
    "n_pi = 100\n",
    "c_vals = np.tile(10**np.linspace(-2,-11,n_c),n_v0).reshape(n_v0,n_c)\n",
    "pi_vals = np.linspace(0.01,0.99,n_pi)\n",
    "v0_vals = np.repeat(10**np.linspace(2,11,n_v0),n_c).reshape(n_v0,n_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 25}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize = (10,10))\n",
    "fig.set_facecolor('white')\n",
    "axs.set_facecolor('white')\n",
    "for i in range(n_v0):\n",
    "    plt.plot(intersection(c_vals[i],v0_vals[i]), label = r\"$v_0 = 1e+{0}$\".format(i+2), linewidth = 3)\n",
    "    plt.xlabel(\"c\")\n",
    "    plt.xticks([0,99],[c_vals[0][0],c_vals[0][99]])\n",
    "    plt.ylabel(\"PPI\")\n",
    "plt.title(r\"PPI over ($v_0,c$)\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"spike_precision_plot_vo_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 25}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize = (13,10))\n",
    "fig.set_facecolor('white')\n",
    "axs.set_facecolor('white')\n",
    "for i in range(n_v0):\n",
    "    Elogpi = np.log(pi_vals)\n",
    "    Elog1_pi = np.log(1-pi_vals)\n",
    "    plt.plot(intersection(1e-6,v0_vals[i], Elogpi,Elog1_pi), label = r\"$v_0 = 1e+{0}$\".format(i+2), linewidth = 3)\n",
    "    plt.xlabel(r\"$\\pi$\")\n",
    "    plt.xticks([0,99],[0.01,0.99])\n",
    "    plt.ylabel(\"PPI\")\n",
    "plt.legend(fontsize = 20,loc='upper center', bbox_to_anchor=(1.2, 0.75),\n",
    "          fancybox=True, shadow=True, ncol=1)\n",
    "plt.title(r\"PPI over ($v_0,\\pi$)\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"spike_precision_plot_vo_pi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP-ML-II run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulation settings\n",
    "\"\"\"\n",
    "# Simulation settings\n",
    "n=300\n",
    "ntest=0\n",
    "p=100\n",
    "q=5\n",
    "noise_ratio=0.05\n",
    "corr=0\n",
    "\n",
    "np.random.seed(333)\n",
    "X = np.random.multivariate_normal(np.zeros(p), np.diag(np.ones(p))*(1-corr)+corr, n)\n",
    "a = np.linspace(1,1/q,q)\n",
    "f = np.sin(a*X[:,:q])\n",
    "if q>1:\n",
    "    f = np.sum(f,1)\n",
    "noise_var = noise_ratio*np.var(f)\n",
    "Y = (f + np.random.normal(0,noise_var**0.5,n)).reshape(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running GP on data\n",
    "\"\"\"\n",
    "results_MLII = fit.VB_EM_GP_SS(Y, X, l0 = 0.01,lmbda0=1, GP_fit_tol = 1e-5, min_VBEM_iter = 1, max_VBEM_iter = 1, max_GP_fit_iter = 200, init_GP_iter = 200, VBEM_tol = 0.01, \n",
    "                              s0 = np.var(Y), sig0 = np.var(Y)**0.5, optimisation = \"adam\",sampling_strat = \"unif\",\n",
    "                              ELBO_sample = np.min((1000,n)), learn_rate = 0.01, subsample = n, newsumgrads=False, \n",
    "                              nn_fraction = 1, iter_remove = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font ={'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "plt.rcParams.update({'text.color' : \"black\",\n",
    "                      'xtick.color' : \"black\",\n",
    "                      'ytick.color' : \"black\",\n",
    "                     'axes.labelcolor' : \"black\"})\n",
    "fig,axs = plt.subplots(figsize=(15,15))\n",
    "fig.set_facecolor('white')\n",
    "axs.set_facecolor('white')\n",
    "axs.set_xlabel(\"Variable\")\n",
    "axs.set_ylabel(\"Inverse lengthscales \" + r'$(\\theta)$')\n",
    "axs.set_title(r\"ML-II GP inverse lengthscales: $d={1}$, $\\sigma^2 = {0}$\".format(noise_ratio,p), fontsize=40)\n",
    "plt.bar(range(p),height = np.sort(np.abs(results_MLII[0][0]))[::-1], color = \"orange\", width = 0.5+(p>10)*0.35)\n",
    "plt.axvline(x=q-0.5, color = \"black\", linestyle = \"--\", lw = 2)\n",
    "fig.savefig(\"ML_II_ls_allinclude_noise={0}_d={1}_n={2}\".format((noise_ratio>0.01)*1,p,n))# CHANGE FOR NOISE AND N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing sequence of marginal likelihoods for sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting ML profiles for different ML-II solutions\n",
    "\"\"\"\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Adding jitter for multiple runs\n",
    "jitter = 1e-2\n",
    "runs = 1\n",
    "reg=0.01\n",
    "\n",
    "plt.rcParams.update({'text.color' : \"black\",\n",
    "                      'xtick.color' : \"black\",\n",
    "                      'ytick.color' : \"black\",\n",
    "                     'axes.labelcolor' : \"black\"})\n",
    "fig,axs = plt.subplots(figsize=(15,15))\n",
    "fig.set_facecolor('white')\n",
    "axs.set_facecolor('white')\n",
    "axs.set_xlabel(r'# variables selected')\n",
    "axs.set_ylabel(r'$logp(y|\\theta)$')\n",
    "\n",
    "l = np.zeros(p)\n",
    "order =  np.argsort(np.abs(results_MLII[0][0]))[::-1]\n",
    "t = time.time()\n",
    "for j in range(runs):\n",
    "    if j < runs-1:\n",
    "        jit = np.random.normal(0,jitter,p)\n",
    "    else:\n",
    "        jit = np.zeros(p)   \n",
    "\n",
    "    logl_est = np.zeros(100)\n",
    "    for i in [4,99]:\n",
    "        \n",
    "        not_selected = order[(i+1):]\n",
    "        selected = order[:(i+1)]\n",
    "        l[not_selected] = 0\n",
    "        results = fit.VB_EM_GP_SS(Y, X[:,selected], l0 = results_MLII[0][0][selected],lmbda0=1, GP_fit_tol = 1e-5, min_VBEM_iter = 1, max_VBEM_iter = 1, max_GP_fit_iter = 100, init_GP_iter = 100, VBEM_tol = 0.01, \n",
    "                              s0 = np.var(Y), sig0 = np.var(Y)**0.5, optimisation = \"adam\",sampling_strat = \"unif\",\n",
    "                              ELBO_sample = np.min((1000,n)), learn_rate = 0.01, subsample = n, newsumgrads=False, \n",
    "                              nn_fraction = 1, iter_remove = False, print_VBEM=False)\n",
    "        l[selected]=results[0][0]\n",
    "        K = kernel_funcs.ARD_lm(l,results[1],X, kern=kernel_funcs.gaussian)\n",
    "        Ktild = K+np.diag(np.ones(n))*(results[2]**2+reg)\n",
    "        logl_est[i] = model_funcs.logL(Y,Ktild)\n",
    "        print(logl_est[i])\n",
    "        \n",
    "    if j==(runs-1):\n",
    "        plt.plot(np.linspace(1,100,100), logl_est, color =\"red\", lw=2, zorder=11)\n",
    "        plt.axvline(x=5, linestyle = \"--\", color = \"black\")\n",
    "    else:\n",
    "        plt.plot(np.linspace(1,100,100), logl_est, color =\"pink\", zorder=11)\n",
    "if noise_ratio>0.01:\n",
    "    legend = plt.legend(fontsize = 30)\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "    frame.set_edgecolor('white')\n",
    "plt.title(r\"ML-II GP MLL profile $d={1}$, $\\sigma^2 = {0}$\".format(noise_ratio, p), Fontsize=40)\n",
    "plt.show()\n",
    "fig.savefig(\"ML_overfit_noise={0}_n={1}_d={2}\".format(1*(noise_ratio>=0.1), n,p))  # CHANGE FOR NOISE AND N\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting ML-II solutions for including all variables, and only including correct variables\n",
    "\"\"\"\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Adding jitter for multiple runs\n",
    "jitter = 1e-2\n",
    "runs = 100\n",
    "reg=0.01\n",
    "\n",
    "order =  np.argsort(np.abs(results_MLII[0][0]))[::-1]\n",
    "t = time.time()\n",
    "logl_est = np.zeros((runs,2))\n",
    "iterr=0\n",
    "for i in [4,99]:\n",
    "    not_selected = order[(i+1):]\n",
    "    selected = order[:(i+1)]\n",
    "    l[not_selected] = 0\n",
    "    results = fit.VB_EM_GP_SS(Y, X[:,selected], l0 = results_MLII[0][0][selected],lmbda0=1, GP_fit_tol = 1e-5, min_VBEM_iter = 1, max_VBEM_iter = 1, max_GP_fit_iter = 100, init_GP_iter = 100, VBEM_tol = 0.01, \n",
    "                          s0 = np.var(Y), sig0 = np.var(Y)**0.5, optimisation = \"adam\",sampling_strat = \"unif\",\n",
    "                          ELBO_sample = np.min((1000,n)), learn_rate = 0.01, subsample = n, newsumgrads=False, \n",
    "                          nn_fraction = 1, iter_remove = False, print_VBEM=False)\n",
    "    for j in range(runs):\n",
    "        if j < runs-1:\n",
    "            jit = np.random.normal(0,jitter,p)\n",
    "        else:\n",
    "            jit = np.zeros(p) \n",
    "        l[selected]=results[0][0]+jit[:i+1]\n",
    "        K = kernel_funcs.ARD_lm(l,results[1],X, kern=kernel_funcs.gaussian)\n",
    "        Ktild = K+np.diag(np.ones(n))*(results[2]**2+reg)\n",
    "        logl_est[j,iterr] = model_funcs.logL(Y,Ktild)\n",
    "    print(\"likelihood for {0} variables included is :\".format(i+1), logl_est[0,iterr])\n",
    "    iterr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean and sd plot\n",
    "\"\"\"\n",
    "Table = logl_est.T\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 32}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "inds = [1,2]\n",
    "c0 = \"blue\"\n",
    "c1 = \"red\"\n",
    "c2 = \"grey\"\n",
    "colours = [np.concatenate((np.repeat(c0,1),np.repeat(c1,1))),np.repeat(c2,5)]\n",
    "xlim = [(0.1,0.25), (0.5,1.01), (2,100)]\n",
    "names = [\"True model\", \"All variables included\"]\n",
    "quantiles = [0.75,0.95,0.99]\n",
    "linestyles = [\"-\", \"--\",\"--\"]\n",
    "lws = [3,1.5,1.5]\n",
    "\n",
    "# Creating plots of results\n",
    "from matplotlib import rcParams, rc_file_defaults\n",
    "Metric_names = [\"log marginal likelihood\"]\n",
    "labelsize = 20\n",
    "rc_file_defaults()\n",
    "rcParams['xtick.labelsize'] = labelsize\n",
    "rcParams['ytick.labelsize'] = labelsize \n",
    "\n",
    "fig,axs = plt.subplots(nrows=1, ncols=1, figsize = (10,10))\n",
    "fig.suptitle(r\"Toyexample: marginal likelihoods obtained in neighbourhood of ML-II optimum\", fontsize = 25, y = 1.2)\n",
    "axs.set_title(Metric_names[0], Fontsize = 20)\n",
    "axs.set_yticks(inds[::-1])\n",
    "means = np.mean(Table,1)[::-1]\n",
    "sd = np.var(Table,1)[::-1]**0.5\n",
    "axs.set_yticklabels(names)\n",
    "axs.scatter(means,inds, color =colours[0][::-1], s = 200, label = \"mean\",zorder = 12, edgecolors = \"black\")\n",
    "for i in range(runs):\n",
    "    axs.scatter(Table[:,i],inds[::-1], color =colours[0], s = 100,zorder = 12, edgecolors = \"black\")\n",
    "plt.legend(fontsize=16, loc = (0.1,-0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"Toy_plots\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSVGP run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running sequence of values for algorithm\n",
    "kern = kernel_funcs.gaussian\n",
    "testing_algorithm = partial(diagnostics.get_pred_posterior_GP,reg = 0.01 ,kern = kern, latents = False)\n",
    "hyper_vals = [1e+4*2**np.linspace(np.log2(100),-np.log2(100),11),1e-4*2**np.linspace(np.log2(100),-np.log2(100),11)]\n",
    "hyper_arg = [\"v0\", \"v1\"]\n",
    "best_loss, best_val, losses, Results = fit.hyper_opt_SSGP(\n",
    "                                    Y, X, fit.VB_EM_GP_SS, testing_algorithm, hyper_arg, hyper_vals, method =  \"ML\", folds = 5, metric = \"elbo\", \n",
    "                                    training_args=[\"final_ELBO_sample\", \"ELBO_sample\", \"v0\", \"seed\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"subsample\", \"sampling_strat\", \"min_VBEM_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"learn_rate_mult\"], \n",
    "                                    training_arg_vals=[1,                   1000,      1e+4,  1,        True,          False,      0.025,              64,    \"unif\" ,            5,                10 ,           1e-5,         0.1/p,          1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out new nn function\n",
    "log_predictives = np.zeros(len(Results))\n",
    "KL = np.zeros(len(Results))\n",
    "t = time.time()\n",
    "for i in range(len(Results)):\n",
    "    log_predictives[i] =  diagnostics.get_pred_posterior_GP_NN_CV(Y,X,Results[i],0.01,kernel_funcs.gaussian,NN=64, fraction=1,post_var=True, print_=True, use_tree=False, leaf_size=100, seed=0)\n",
    "    KL[i] = diagnostics.get_KL(Results[i],10**4,10**-4,10**-3,10**-3)\n",
    "    print(log_predictives[i])\n",
    "print(time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing CV_hyperopt to get model weights with ELPD\n",
    "mse = True\n",
    "elbos = np.zeros(len(Results))\n",
    "for j in range(len(Results)):\n",
    "    if mse:\n",
    "        elbos[j]=log_predictives[j]#+KL[j]\n",
    "    else:\n",
    "        elbos[j] = Results[j][len(Results[j])-1]\n",
    "max_elbo = np.max(elbos)\n",
    "\n",
    "weights = np.zeros(len(Results))\n",
    "# Getting weighted PIPS and L\n",
    "Lmbda = np.zeros((len(Results), p))\n",
    "Ls = np.zeros((len(Results), p))\n",
    "for j in range(len(Results)):\n",
    "    Lmbda[j] = Results[j][3]\n",
    "    Ls[j] = np.abs(Results[j][0][0])\n",
    "    elbo = elbos[j]\n",
    "    if elbo < max_elbo-500:\n",
    "        weights[j]==0\n",
    "    else:\n",
    "        weights[j] = np.exp(elbos[j]-max_elbo)\n",
    "weights = weights/weights.sum()\n",
    "print(weights)\n",
    "where = np.where(Lmbda>0.01)\n",
    "for i in range(10):\n",
    "    print(where[1][np.where(where[0]==i)])\n",
    "PIP = Lmbda.T @ weights\n",
    "l = Ls.T @ weights\n",
    "plt.plot(Lmbda+np.random.normal(0,0.01,len(Results)*p).reshape(len(Results),p));\n",
    "plt.show()\n",
    "plt.plot(Ls)\n",
    "plt.show()\n",
    "plt.rcParams.update({'text.color' : \"black\",\n",
    "                      'xtick.color' : \"black\",\n",
    "                      'ytick.color' : \"black\",\n",
    "                     'axes.labelcolor' : \"black\"})\n",
    "fig = plt.figure(figsize = (20,7))\n",
    "fig.set_facecolor('white')\n",
    "plt.title(\"PIPs for dense toy example\")\n",
    "plt.bar(range(p), PIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use these plots for varying coefficients \"\"\"\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.ylabel(r\"$|\\langle \\theta \\rangle| $\")\n",
    "plt.xlabel(r\"$log_2(v_0)-log_2(10^4)$\")\n",
    "plt.title(r\"Inverse lengthscales ($\\theta$) : $d={0}$\".format(p))\n",
    "plt.xticks(np.linspace(0,19,20),np.round(np.linspace(np.log2(100),-np.log2(100),20),1), fontsize = 15)\n",
    "plt.plot(Ls, lw=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"variable_inclusion_plot_toyexample_d={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(15,10))\n",
    "plt.xlabel(r\"$log_2(v_0)-log_2(10^4)$\")\n",
    "plt.xticks(np.linspace(0,19,20),np.round(np.linspace(np.log2(100),-np.log2(100),20),1), fontsize = 15)\n",
    "plt.title(r\"Toy example: Mean PIP $(\\bar \\lambda)$ solution path\")\n",
    "plt.ylabel(r\"$\\lambda$\")\n",
    "plt.plot(np.mean(Lmbda,1), \"blue\", lw=2)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"total_PIP_toyexample_d={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(15,10))\n",
    "plt.xlabel(r\"$log_2(v_0)-log_2(10^4)$\")\n",
    "plt.xticks(np.linspace(0,19,20),np.round(np.linspace(np.log2(100),-np.log2(100),20),1), fontsize = 15)\n",
    "plt.title(r\"Toy example: LOO-LPD\")\n",
    "plt.plot(log_predictives, color = \"blue\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"log_predictives_toyexample_d={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.title(r\"SSVGP marginal PIPs ($\\lambda$): $d={0}$\".format(p))\n",
    "plt.scatter(range(p),np.sort(PIP)[::-1], color = \"red\", s=200, marker = \"o\")\n",
    "#plt.bar(range(p),np.sort(PIP)[::-1], color = \"crimson\", width = 0.5)\n",
    "plt.ylim(-0.02,1.05)\n",
    "plt.axvline(x=q-0.5, linestyle = \"--\", color = \"black\", label = \"LHS: true inclusions / RHS : true exclusions\", lw = 2)\n",
    "plt.legend(fontsize = 18)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "frame.set_edgecolor('white')\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Marginal_PIPs_toyexample_d={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.title(r\"ML-II inverse lengthscales: $d={0}$\".format(p))\n",
    "plt.bar(range(p),np.sort(np.abs(results_MLII[0][0]))[::-1], color = \"orange\", width = 0.5+0.3*(p>10))\n",
    "plt.axvline(x=q-0.5, linestyle = \"--\", color = \"black\", label = \"LHS: true inclusions / RHS : true exclusions\", lw = 2)\n",
    "plt.legend(fontsize = 18)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "frame.set_edgecolor('white')\n",
    "plt.ylim(-0.02,np.max(np.abs(l))+0.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"ML-II ILS toy_example={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.title(r\"SSVGP posterior mean ILS ($\\bar \\mu$): $d={0}$\".format(p))\n",
    "plt.bar(range(p),np.sort(l)[::-1], color = \"red\", width = 0.5+0.3*(p>10))\n",
    "#plt.scatter(range(p),np.sort(l)[::-1], color = \"red\", s=500, marker = \"X\")\n",
    "plt.axvline(x=q-0.5, linestyle = \"--\", color = \"black\", label = \"LHS: true inclusions / RHS : true exclusions\", lw = 2)\n",
    "plt.legend(fontsize = 18)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "frame.set_edgecolor('white')\n",
    "plt.ylim(-0.02,np.max(np.abs(l))+0.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Marginal_ILS_toyexample_d={0}\".format(p), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.title(r\"SSVGP marginal PIPs ($\\lambda$): $d={0}$\".format(p))\n",
    "plt.scatter(range(p),np.sort(PIP)[::-1], color = \"red\", s=200, marker = \"o\")\n",
    "#plt.bar(range(p),np.sort(PIP)[::-1], color = \"crimson\", width = 0.5)\n",
    "plt.ylim(-0.02,1.05)\n",
    "plt.axvline(x=q-0.5, linestyle = \"--\", color = \"black\", label = \"LHS: true inclusions / RHS : true exclusions\", lw = 2)\n",
    "#plt.legend(fontsize = 18)\n",
    "#frame = legend.get_frame()\n",
    "#frame.set_facecolor('white')\n",
    "#frame.set_edgecolor('white')\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Marginal_PIPs_toyexample_d={0}\".format(p), bbox_inches = \"tight\")\n",
    "\n",
    "plt.rc('axes',edgecolor='black')\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "fig,axs = plt.subplots(figsize=(12,10))\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.title(r\"SSVGP posterior mean ILS ($\\bar \\mu$): $d={0}$\".format(p))\n",
    "plt.bar(range(p),np.sort(l)[::-1], color = \"red\", width = 0.5+0.3*(p>10))\n",
    "#plt.scatter(range(p),np.sort(l)[::-1], color = \"red\", s=500, marker = \"X\")\n",
    "plt.axvline(x=q-0.5, linestyle = \"--\", color = \"black\", label = \"LHS: true inclusions / RHS : true exclusions\", lw = 2)\n",
    "#plt.legend(fontsize = 18)\n",
    "#frame = legend.get_frame()\n",
    "#frame.set_facecolor('white')\n",
    "#frame.set_edgecolor('white')\n",
    "plt.ylim(-0.02,np.max(np.abs(l))+0.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Marginal_ILS_toyexample_d={0}\".format(p), bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
