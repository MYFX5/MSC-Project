{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: SSVGP-LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Importing and defining all required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing in libraries\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import inspect\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "Importing algorithm functions\n",
    "\"\"\"\n",
    "import os\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/GP algorithms/Master function files')\n",
    "from GP_funcs_FRSS import kernel_funcs\n",
    "from GP_funcs_FRSS import model_funcs\n",
    "from GP_funcs_FRSS import draw_GP\n",
    "from GP_funcs_FRSS import fit\n",
    "from GP_funcs_FRSS import diagnostics\n",
    "from GP_funcs_FRSS import simulations\n",
    "from functools import partial\n",
    "os.chdir('C:/Users/hughw/Documents/MSC project/Simulation results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Setting simulation parameters and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulation controls\n",
    "\"\"\"\n",
    "# Simulation settings\n",
    "n=300\n",
    "ntest=100\n",
    "p=100\n",
    "q=5\n",
    "corr=0.5 # used for GP draw\n",
    "r2=0.9 # used for GP draw\n",
    "lsmean=0.25\n",
    "sigma2=1\n",
    "ltrue=np.ones(p)*lsmean/q**0.5\n",
    "strue=1\n",
    "\n",
    "nruns = 50\n",
    "\n",
    "\n",
    "# Model run settings\n",
    "nmodels = 1\n",
    "VS_threshs = [[0.5,0.9,0.95,0.99]]\n",
    "iter_remove = [False]\n",
    "sampling_strat = [\"unif\"]\n",
    "minibatch_size = [150]\n",
    "GPtol=[1e-5]\n",
    "MC_pred = [True]\n",
    "predict_selected = [False]\n",
    "post_fit = [False]\n",
    "train = [True] \n",
    "base = [0.025]\n",
    "hyper_opt = [True]\n",
    "model_select = [False]\n",
    "post_var = [False]\n",
    "model_weights = [\"elpd\"]\n",
    "min_VBEM_iter = [5]\n",
    "max_VBEM_iter = [10]\n",
    "gp_iter = [100]\n",
    "opt = [\"amsgrad\"]\n",
    "l_init = 0.01\n",
    "beta2=0.99\n",
    "t = len(VS_threshs[0])\n",
    "kern=kernel_funcs.gaussian\n",
    "grad_kern=kernel_funcs.grad_gaussian\n",
    "reg = 0.01\n",
    "NN_pred = False\n",
    "newsumgrads = False\n",
    "VBtol=0.1/p\n",
    "temp=1\n",
    "v0=1e+4\n",
    "v1=1e-4\n",
    "postfit = \"mixed\"\n",
    "# SEE BELOW FOR ARGVALS\n",
    "\n",
    "# Storage objects\n",
    "m=nmodels\n",
    "Runtime=np.zeros((nruns, m))\n",
    "Lambda = np.zeros((nruns, m, p))\n",
    "L = np.zeros((nruns, m, p))\n",
    "L1norm=np.zeros((nruns, m))\n",
    "L2norm=np.zeros((nruns, m))\n",
    "MSE_F=np.zeros((nruns, m))\n",
    "MSE_Y=np.zeros((nruns,m))\n",
    "Acc=np.zeros((nruns,m,t))\n",
    "Weighted_Acc=np.zeros((nruns,m,t))\n",
    "TPR=np.zeros((nruns,m,t))\n",
    "TNR=np.zeros((nruns,m,t))\n",
    "PPV=np.zeros((nruns,m,t))\n",
    "NPV=np.zeros((nruns,m,t))\n",
    "AUC=np.zeros((nruns,m))\n",
    "MCC=np.zeros((nruns,m,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Running results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8750)\n",
    "runlist = np.random.choice(1000,nruns,False) # Choose 100 random trials\n",
    "for run in range(len(runlist)):\n",
    "#for run in [27,30]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Generating data and scaling data\n",
    "    \"\"\"\n",
    "    lselect=[]\n",
    "    np.random.seed(runlist[run]) # Fixing trial seed\n",
    "    t=time.time()\n",
    "    Y,F,X,e,lselect,strue,sigma,select=draw_GP.draw_GP_ARD_lm(n,ntest,p,q,sigma2,corr,strue,ltrue,plot_YX=True,kern=kern,cop=False,r2=r2)\n",
    "    \n",
    "    Y = Y.reshape(n+ntest,1)\n",
    "    F = F.reshape(n+ntest,1)\n",
    "    \n",
    "    Y = (Y-Y[:n].mean())/Y[:n].var()**0.5\n",
    "    X = (X-X[:n].mean(0))/X[:n].var(0)**0.5\n",
    "    F = (F-F[:n].mean())/F[:n].var()**0.5\n",
    "\n",
    "    # Getting training and test set\n",
    "    ytest=Y[n:]\n",
    "    Xtest=X[n:]\n",
    "    ftest=F[n:]\n",
    "    y=Y[:n]\n",
    "    X=X[:n]\n",
    "    f=F[:n]\n",
    "    print(\"data generated\")\n",
    "    if lselect.any():\n",
    "        print(\"Length-scales are: \",lselect[select])\n",
    "    print(\"Noise variance is: \",sigma**2)\n",
    "    print(\"Average data variance is: \", np.mean(np.var(X,0)))\n",
    "    print(\"Time taken to draw data : \", time.time()-t)\n",
    "    \n",
    "    \"\"\"\n",
    "    Running algorithm\n",
    "    \"\"\"\n",
    "    args = []\n",
    "    arg_vals = []\n",
    "    for i in range(nmodels):\n",
    "        args.append([\"k\",\"L0\",\"seed\",\"subsample\",\"svi_subsample\", \"sampling_strat\", \"min_VBEM_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"max_GP_fit_iter\", \"ZT_init_iter\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"optimisation\", \"final_prune\"])\n",
    "        arg_vals.append([10,1e-2,0,minibatch_size[i], 5,sampling_strat[i], min_VBEM_iter[i], max_VBEM_iter[i], GPtol[i], 0.1/p, gp_iter[i],gp_iter[i], iter_remove[i], False, base[i], opt[i], True])\n",
    "\n",
    "    test_algorithm = partial(diagnostics.get_pred_posterior_GP,reg = reg,kern = kernel_funcs.gaussian)\n",
    "\n",
    "    Runtime[run], Lambda[run], L[run], V, L1norm[run], L2norm[run], MSE_F[run], MSE_Y[run], Acc[run], Weighted_Acc[run], TPR[run], TNR[run], PPV[run], NPV[run], AUC[run], MCC[run]= simulations.do_simulation_VBEMSSGP(\n",
    "                               y, X, ftest, ytest, Xtest, q, algorithm_training = fit.VB_EM_GP_SS, algorithm_testing = test_algorithm, \n",
    "                               nmodels = m, args = args, arg_vals = arg_vals, SS_GP = [True], post_var = post_var,\n",
    "                               order_relevant_vars = False, order_irrelevant_vars = False, VS_threshs = VS_threshs, \n",
    "                               select = select, predict_selected = predict_selected, hyper_opt = hyper_opt, hyper_arg = [\"v0\",\"v1\"],\n",
    "                                hyper_vals = [1e+4*2**np.linspace(np.log2(100),-np.log2(100),11),1e-4*2**np.linspace(np.log2(100),-np.log2(100),11)], ltrue=lselect, MC_pred = MC_pred, model_select = model_select, post_fit_subsample=n, train = train,\n",
    "                                model_weighting = model_weights)\n",
    "    \n",
    "    print(\"RUN {0}\".format(run))\n",
    "    print(\"Runtime mean is:\", Runtime[:run+1].mean(0))\n",
    "    print(\"Weighted accuracy mean is:\", Weighted_Acc[:run].mean(0))\n",
    "    print(\"TPR mean is:\", TPR[:run+1].mean(0))\n",
    "    print(\"PPV mean is:\", PPV[:run+1].mean(0))\n",
    "    print(\"MCC mean is:\", MCC[:run+1].mean(0))\n",
    "    print(\"L1norm mean is:\", L1norm[:run+1].mean(0))\n",
    "    print(\"L2norm mean is:\", L2norm[:run+1].mean(0))\n",
    "    print(\"MSE_F mean is:\", MSE_F[:run+1].mean(0))\n",
    "    print(\"MSE_Y mean is:\", MSE_Y[:run+1].mean(0), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    args = []\n",
    "    arg_vals = []\n",
    "    for i in range(nmodels):\n",
    "        args.append([\"k\",\"L0\",\"seed\",\"subsample\",\"svi_subsample\", \"sampling_strat\", \"min_VBEM_iter\", \"max_VBEM_iter\", \"GP_fit_tol\", \"VBEM_tol\", \"max_GP_fit_iter\", \"ZT_init_iter\", \"iter_remove\", \"print_VBEM\", \"learn_rate\", \"optimisation\", \"final_prune\"])\n",
    "        arg_vals.append([10,1e-2,0,minibatch_size[i], 1,sampling_strat[i], min_VBEM_iter[i], max_VBEM_iter[i], GPtol[i], 0.1/p, gp_iter[i],gp_iter[i], iter_remove[i], False, step[i], opt[i], True])\n",
    "\n",
    "best_pair,selection_path,losses,Results =  fit.hyper_opt_SSGP(y, X, fit.VB_EM_GP_SS, test_algorithm, [\"v0\",\"v1\"],  [1e+4*2**np.linspace(np.log2(100),-np.log2(100),11),1e-4*2**np.linspace(np.log2(100),-np.log2(100),11)], \n",
    "                                                                              method =  \"ML\", training_args=args[0],training_arg_vals=arg_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    print(np.sum(Results[i][0]!=0))\n",
    "    \n",
    "Results[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logevidences = np.zeros(len(Results))\n",
    "for i in range(len(Results)):\n",
    "    logevidences[i] =  diagnostics.get_pred_posterior_GP_NN_CV(y,X,Results[i],0.01,kern=kernel_funcs.gaussian,NN=n, fraction=1,post_var=True, print_=False, use_tree=False, leaf_size=100, seed=0, MC_iters = 1)\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIP,Ls,Ss,Sigs = np.zeros((len(Results), p)),np.zeros((len(Results), p)),np.zeros((len(Results), )),np.zeros((len(Results), ))\n",
    "weights = np.zeros(len(Results))\n",
    "max_logevidence = np.max(logevidences)\n",
    "\n",
    "# Do weighting\n",
    "for i in range(len(Results)):\n",
    "    logevidence = logevidences[i]\n",
    "    if logevidence >= max_logevidence-500:\n",
    "        if model_select[0]:\n",
    "            weights[i] = (logevidence==max_logevidence)*1\n",
    "        else:\n",
    "            weights[i] = np.exp(logevidence-max_logevidence)\n",
    "    PIP[i] = Results[i][4]\n",
    "    Ls[i] = np.abs(Results[i][0])\n",
    "    Ss[i] = Results[i][2]\n",
    "    Sigs[i] = Results[i][3]\n",
    "weights = weights/weights.sum()\n",
    "l = [Ls.T @ weights]\n",
    "s = np.sum(Ss*weights)\n",
    "sig = np.sum(Sigs*weights)\n",
    "lmbda = PIP.T @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\"Runtime\", \"MSE_F\", \"MSE_Y\", \"Acc\", \"Weighted_Acc\", \"TPR\", \"TNR\", \"PPV\", \"NPV\", \"AUC\", \"MCC\"]\n",
    "objlist = [Runtime, MSE_F, MSE_Y, Acc, Weighted_Acc, TPR, TNR, PPV, NPV, AUC, MCC]\n",
    "#iters = np.random.choice(1000,100,False)\n",
    "iters = np.linspace(0,49,50).astype(int)\n",
    "\n",
    "for i in range(len(objlist)):\n",
    "    print(\"Mean {0} is:\".format(namelist[i]), np.mean(objlist[i][iters],0))\n",
    "\n",
    "print(\"\\n\")\n",
    "for i in range(len(objlist)):\n",
    "    print(\"Median {0} is:\".format(namelist[i]), np.median(objlist[i][iters],0))\n",
    "\n",
    "print(\"\\n\")\n",
    "quant = 0.25\n",
    "for i in range(len(objlist)):\n",
    "    if namelist[i] in [\"Runtime\", \"MSE_F\", \"MSE_Y\"]:\n",
    "        print(\"{1} quantile {0} is:\".format(namelist[i], quant), np.quantile(objlist[i][iters],1-quant,0))\n",
    "    else:\n",
    "        print(\"{1} quantile {0} is:\".format(namelist[i], quant), np.quantile(objlist[i][iters],quant,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "Output = {\"Runtime\" : Runtime, \"Lambda\" : Lambda, \"L\" : L, \"L1norm\" : L1norm, \"L2norm\" : L2norm, \"MSE_F\" : MSE_F\n",
    "        , \"MSE_Y\" : MSE_Y, \"Acc\" : Acc, \"Weighted_Acc\" : Weighted_Acc, \"TPR\" :TPR, \"TNR\" : TNR, \"PPV\" : PPV, \"NPV\" : NPV, \"AUC\" : AUC, \"MCC\" : MCC}\n",
    "String = \"Stage1_LR{13}_{0}_{1}_lsmean={12}_r2={14}_l0={2}_b2={3}_step={4}_MCpred={5}_n={6}_p={7}_q={8}_kern={9}_runs={10}_start={11}\".format(\n",
    "    \"GP\", date.today(), l_init, beta2, step[0], MC_pred[0],n,p,q,str(kern)[23:28], nruns, \"random\", lsmean, minibatch_size, r2)\n",
    "np.save(String, Output) # saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
